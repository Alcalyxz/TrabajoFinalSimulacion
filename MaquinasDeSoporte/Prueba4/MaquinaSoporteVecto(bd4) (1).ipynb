{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MaquinaSoporteVecto(bd4).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW-L-PQS01dY"
      },
      "source": [
        "from scipy.io import loadmat\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "\r\n",
        "scaler=StandardScaler()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "F9WegNwo2Wv0",
        "outputId": "116f07ea-0442-453b-dbfc-0cb8a3bad013"
      },
      "source": [
        "##---------------DATOS DE ENTRENAMIENTO -------------------------##\r\n",
        "##Cargar los datos con extenci√≥n .mat\r\n",
        "x = loadmat('/DatosPrueba4.mat')\r\n",
        "\r\n",
        "##Traernos los datos del archivo .mat que nos interesan\r\n",
        "y = x['data_tr']\r\n",
        "\r\n",
        "##Convertir los datos en un array de Numpy\r\n",
        "z = np.array(y)\r\n",
        "\r\n",
        "##Convertir el Array en un DataFrame de Pandas\r\n",
        "df = pd.DataFrame(z)\r\n",
        "\r\n",
        "##Contar el numero de datos nulos del dataFrame\r\n",
        "np.count_nonzero(pd.isnull(df) == True)\r\n",
        "\r\n",
        "df.columns = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','Label']\r\n",
        "df.sample(8)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>911</th>\n",
              "      <td>0.000409</td>\n",
              "      <td>0.000826</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>2.214416</td>\n",
              "      <td>3.091875</td>\n",
              "      <td>0.002702</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000918</td>\n",
              "      <td>101.52</td>\n",
              "      <td>38.160872</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.078866</td>\n",
              "      <td>-2.013617</td>\n",
              "      <td>138.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>108.388191</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>0.060528</td>\n",
              "      <td>0.265940</td>\n",
              "      <td>0.000402</td>\n",
              "      <td>0.000351</td>\n",
              "      <td>6.185386</td>\n",
              "      <td>40.481851</td>\n",
              "      <td>2.110700</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.271441</td>\n",
              "      <td>597.50</td>\n",
              "      <td>584.209014</td>\n",
              "      <td>231.0</td>\n",
              "      <td>13.3434</td>\n",
              "      <td>1.236930</td>\n",
              "      <td>-0.353301</td>\n",
              "      <td>1676.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>833.602675</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872</th>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.000221</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>1.433364</td>\n",
              "      <td>0.620202</td>\n",
              "      <td>0.000707</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000271</td>\n",
              "      <td>110.64</td>\n",
              "      <td>36.663780</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.574605</td>\n",
              "      <td>-1.686394</td>\n",
              "      <td>138.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>116.498927</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>0.000203</td>\n",
              "      <td>0.000382</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>1.730696</td>\n",
              "      <td>1.152273</td>\n",
              "      <td>0.001114</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000431</td>\n",
              "      <td>125.52</td>\n",
              "      <td>32.500033</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-1.337521</td>\n",
              "      <td>0.040578</td>\n",
              "      <td>155.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>129.618517</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>0.011189</td>\n",
              "      <td>0.022381</td>\n",
              "      <td>0.002011</td>\n",
              "      <td>0.002377</td>\n",
              "      <td>3.062000</td>\n",
              "      <td>9.917885</td>\n",
              "      <td>0.121186</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.024922</td>\n",
              "      <td>1043.06</td>\n",
              "      <td>568.235117</td>\n",
              "      <td>1476.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.617410</td>\n",
              "      <td>-1.540981</td>\n",
              "      <td>1476.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>1186.438536</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>0.004746</td>\n",
              "      <td>0.011220</td>\n",
              "      <td>0.000564</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>4.095941</td>\n",
              "      <td>17.863699</td>\n",
              "      <td>0.068212</td>\n",
              "      <td>0.000239</td>\n",
              "      <td>0.012131</td>\n",
              "      <td>456.23</td>\n",
              "      <td>64.334645</td>\n",
              "      <td>474.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.282448</td>\n",
              "      <td>3.463910</td>\n",
              "      <td>681.0</td>\n",
              "      <td>318.0</td>\n",
              "      <td>460.698784</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>658</th>\n",
              "      <td>0.015497</td>\n",
              "      <td>0.030483</td>\n",
              "      <td>0.005308</td>\n",
              "      <td>0.007240</td>\n",
              "      <td>3.938421</td>\n",
              "      <td>18.446931</td>\n",
              "      <td>0.206535</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>0.034061</td>\n",
              "      <td>750.41</td>\n",
              "      <td>575.279942</td>\n",
              "      <td>477.5</td>\n",
              "      <td>369.9087</td>\n",
              "      <td>0.740268</td>\n",
              "      <td>-1.198228</td>\n",
              "      <td>1676.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>943.796964</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>0.546203</td>\n",
              "      <td>1.808611</td>\n",
              "      <td>0.013419</td>\n",
              "      <td>0.019740</td>\n",
              "      <td>5.119974</td>\n",
              "      <td>29.011126</td>\n",
              "      <td>13.207688</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>1.880612</td>\n",
              "      <td>816.23</td>\n",
              "      <td>672.594732</td>\n",
              "      <td>266.0</td>\n",
              "      <td>65.2344</td>\n",
              "      <td>0.381595</td>\n",
              "      <td>-1.795197</td>\n",
              "      <td>1676.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>1055.505211</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             1         2         3         4  ...      16     17           18  Label\n",
              "911   0.000409  0.000826  0.000113  0.000152  ...   138.0   62.0   108.388191    1.0\n",
              "849   0.060528  0.265940  0.000402  0.000351  ...  1676.0  222.0   833.602675    0.0\n",
              "872   0.000158  0.000221  0.000072  0.000101  ...   138.0   62.0   116.498927    1.0\n",
              "1007  0.000203  0.000382  0.000007  0.000005  ...   155.0   62.0   129.618517    1.0\n",
              "615   0.011189  0.022381  0.002011  0.002377  ...  1476.0  222.0  1186.438536    0.0\n",
              "63    0.004746  0.011220  0.000564  0.000342  ...   681.0  318.0   460.698784    0.0\n",
              "658   0.015497  0.030483  0.005308  0.007240  ...  1676.0  228.0   943.796964    0.0\n",
              "333   0.546203  1.808611  0.013419  0.019740  ...  1676.0  222.0  1055.505211    0.0\n",
              "\n",
              "[8 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YBUkgpG2dsD"
      },
      "source": [
        "YEntrenamiento = df['Label']\r\n",
        "XEntrenamiento = scaler.fit_transform(df.drop(['Label'],axis=1))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsKCraia28cS"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "import itertools as itertools"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU9a4M8c2kTq"
      },
      "source": [
        "def experiementarSVC(x, y, kernels, gammas,params_reg):\r\n",
        "    \"\"\"funci√≥n que realizar experimentos sobre un SVM para clasificaci√≥n\r\n",
        "    \r\n",
        "    x: numpy.Array, con las caracteristicas del problema\r\n",
        "    y: numpy.Array, con la variable objetivo\r\n",
        "    kernels: List[str], lista con valores a pasar \r\n",
        "        a sklearn correspondiente al kernel de la SVM\r\n",
        "    gammas: List[float], lista con los valores a pasar a\r\n",
        "        sklean correspondiente el valor de los coeficientes para usar en el\r\n",
        "        kernel\r\n",
        "    params_reg: List[float], lista con los valores a a pasar a \r\n",
        "        sklearn para ser usados como parametro de regularizaci√≥n\r\n",
        "    \r\n",
        "    retorna: pd.Dataframe con las siguientes columnas:\r\n",
        "        - 3 columnas con los tres parametros: kernel, gamma, param de regularizacion\r\n",
        "        - error cuadratico medio en el cojunto entrenamiento (promedio de los 4 folds)\r\n",
        "        - error cuadratico medio en el cojunto test (promedio de los 4 folds)\r\n",
        "        - % de Vectores de Soporte promedio para los 4 folds (0 a 100)\r\n",
        "    \"\"\"\r\n",
        "    idx = 0\r\n",
        "    kf = StratifiedKFold(n_splits=4)\r\n",
        "    # crear una lista con la combinaciones de los elementos de cada list\r\n",
        "    kernels_gammas_regs = list(itertools.product(kernels, gammas, params_reg))\r\n",
        "    resultados = pd.DataFrame()\r\n",
        "    \r\n",
        "    for params in kernels_gammas_regs:\r\n",
        "        kernel, gamma, param_reg = params\r\n",
        "        print(\"parametros usados\", params) # puede usar para ver los params\r\n",
        "        errores_train = []\r\n",
        "        errores_test = []\r\n",
        "        pct_support_vectors = []        \r\n",
        "        for train_index, test_index in kf.split(x, y):\r\n",
        "            X_train, X_test = x[train_index], x[test_index]\r\n",
        "            y_train, y_test = y[train_index], y[test_index]  \r\n",
        "            # normalizar los datos\r\n",
        "            scaler = StandardScaler()\r\n",
        "            X_train = scaler.fit_transform(X_train)\r\n",
        "            X_test = scaler.transform(X_test)\r\n",
        "            svm = SVC(kernel=kernel, gamma=gamma, C=param_reg, max_iter = 100)\r\n",
        "            # Entrenar el modelo\r\n",
        "            svm.fit(X=X_train, y=y_train)\r\n",
        "            # calculo de errores\r\n",
        "            y_train_pred = svm.predict(X=X_train)\r\n",
        "            y_test_pred = svm.predict(X=X_test)\r\n",
        "            # error y pct de vectores de soporte\r\n",
        "            errores_train.append(accuracy_score(y_true = y_train, y_pred =y_train_pred))\r\n",
        "            errores_test.append(accuracy_score(y_true = y_test, y_pred = y_test_pred))\r\n",
        "            # contar muestras de entrenamiento\r\n",
        "            n_train = X_train.shape[0]\r\n",
        "            pct_vs = (len(svm.support_vectors_)/n_train)*100\r\n",
        "            pct_support_vectors.append(pct_vs)\r\n",
        "        \r\n",
        "        resultados.loc[idx,'kernel'] = kernel\r\n",
        "        resultados.loc[idx,'gamma'] = gamma\r\n",
        "        resultados.loc[idx,'param_reg'] = param_reg\r\n",
        "        resultados.loc[idx,'error de entrenamiento'] = np.mean(errores_train)\r\n",
        "        resultados.loc[idx,'error de prueba'] = np.mean(errores_test)\r\n",
        "        resultados.loc[idx,'% de vectores de soporte'] = np.mean(pct_support_vectors)\r\n",
        "        idx+=1\r\n",
        "    return (resultados)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Uq76skYA2pq1",
        "outputId": "d1955ecf-9931-40c6-93ec-bbac91b8143b"
      },
      "source": [
        "resultadosSVC = experiementarSVC(x = XEntrenamiento,y=YEntrenamiento,\r\n",
        "                                 kernels=['linear', 'rbf'],\r\n",
        "                                 gammas = [0.01,0.1],\r\n",
        "                                 params_reg = [0.001, 0.01,0.1, 1.0,10]\r\n",
        "                                )\r\n",
        "\r\n",
        "resultadosSVC"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "parametros usados ('linear', 0.01, 0.001)\n",
            "parametros usados ('linear', 0.01, 0.01)\n",
            "parametros usados ('linear', 0.01, 0.1)\n",
            "parametros usados ('linear', 0.01, 1.0)\n",
            "parametros usados ('linear', 0.01, 10)\n",
            "parametros usados ('linear', 0.1, 0.001)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "parametros usados ('linear', 0.1, 0.01)\n",
            "parametros usados ('linear', 0.1, 0.1)\n",
            "parametros usados ('linear', 0.1, 1.0)\n",
            "parametros usados ('linear', 0.1, 10)\n",
            "parametros usados ('rbf', 0.01, 0.001)\n",
            "parametros usados ('rbf', 0.01, 0.01)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "parametros usados ('rbf', 0.01, 0.1)\n",
            "parametros usados ('rbf', 0.01, 1.0)\n",
            "parametros usados ('rbf', 0.01, 10)\n",
            "parametros usados ('rbf', 0.1, 0.001)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "parametros usados ('rbf', 0.1, 0.01)\n",
            "parametros usados ('rbf', 0.1, 0.1)\n",
            "parametros usados ('rbf', 0.1, 1.0)\n",
            "parametros usados ('rbf', 0.1, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>gamma</th>\n",
              "      <th>param_reg</th>\n",
              "      <th>error de entrenamiento</th>\n",
              "      <th>error de prueba</th>\n",
              "      <th>% de vectores de soporte</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.969584</td>\n",
              "      <td>0.967091</td>\n",
              "      <td>25.086241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.989026</td>\n",
              "      <td>0.991541</td>\n",
              "      <td>11.508068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999060</td>\n",
              "      <td>3.637348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.285640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10.000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.815283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.969584</td>\n",
              "      <td>0.967091</td>\n",
              "      <td>25.086241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.989026</td>\n",
              "      <td>0.991541</td>\n",
              "      <td>11.508068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999060</td>\n",
              "      <td>3.637348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.285640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.10</td>\n",
              "      <td>10.000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.815283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.967389</td>\n",
              "      <td>0.965211</td>\n",
              "      <td>25.086241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.967702</td>\n",
              "      <td>0.965211</td>\n",
              "      <td>25.086241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.970838</td>\n",
              "      <td>0.968971</td>\n",
              "      <td>25.023506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.995611</td>\n",
              "      <td>0.994361</td>\n",
              "      <td>8.999522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10.000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.229726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.982754</td>\n",
              "      <td>0.983076</td>\n",
              "      <td>25.086241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.982754</td>\n",
              "      <td>0.984019</td>\n",
              "      <td>25.086241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.991534</td>\n",
              "      <td>0.991541</td>\n",
              "      <td>16.776139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.999059</td>\n",
              "      <td>0.999060</td>\n",
              "      <td>8.058650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.10</td>\n",
              "      <td>10.000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999060</td>\n",
              "      <td>6.302653</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    kernel  gamma  ...  error de prueba  % de vectores de soporte\n",
              "0   linear   0.01  ...         0.967091                 25.086241\n",
              "1   linear   0.01  ...         0.991541                 11.508068\n",
              "2   linear   0.01  ...         0.999060                  3.637348\n",
              "3   linear   0.01  ...         1.000000                  1.285640\n",
              "4   linear   0.01  ...         1.000000                  0.815283\n",
              "5   linear   0.10  ...         0.967091                 25.086241\n",
              "6   linear   0.10  ...         0.991541                 11.508068\n",
              "7   linear   0.10  ...         0.999060                  3.637348\n",
              "8   linear   0.10  ...         1.000000                  1.285640\n",
              "9   linear   0.10  ...         1.000000                  0.815283\n",
              "10     rbf   0.01  ...         0.965211                 25.086241\n",
              "11     rbf   0.01  ...         0.965211                 25.086241\n",
              "12     rbf   0.01  ...         0.968971                 25.023506\n",
              "13     rbf   0.01  ...         0.994361                  8.999522\n",
              "14     rbf   0.01  ...         1.000000                  3.229726\n",
              "15     rbf   0.10  ...         0.983076                 25.086241\n",
              "16     rbf   0.10  ...         0.984019                 25.086241\n",
              "17     rbf   0.10  ...         0.991541                 16.776139\n",
              "18     rbf   0.10  ...         0.999060                  8.058650\n",
              "19     rbf   0.10  ...         0.999060                  6.302653\n",
              "\n",
              "[20 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}